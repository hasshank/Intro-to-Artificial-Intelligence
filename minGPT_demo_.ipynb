{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import Dataloder\n",
        "from mingpt.utils import set_seed\n",
        "set _seed(3407)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "  class SortDataset(Dataset):\n",
        "\n",
        "    def __init__(self, split, length=6, num_digits=3):\n",
        "      assert split in {\"train\", test}\n",
        "      self.split = split\n",
        "      self.length = length\n",
        "      self.num_digits = num_digits\n",
        "\n",
        "    def __len__(self):\n",
        "      return 10000\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "      return self.num_digits\n",
        "\n",
        "    def get_block_size(self):\n",
        "      return self.length *2 -1\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "      while true:\n",
        "        inp = torch.randit(self.num_digits, size =(self.length,), dtype=torch.long)\n",
        "        if torch.rand(1).item() < 0.5:\n",
        "          if inp.unique().nelement() > self.length // 2:\n",
        "            continue\n",
        "\n",
        "        h = hash(pickle.dumps(inp.tolist()))\n",
        "        inp_split = \"test\" if h % 4 == 0 else \"train\"\n",
        "        if inp_split == self.split:\n",
        "          break\n",
        "\n",
        "      sol = torch.sort(inp)[0]\n",
        "\n",
        "      cat = torch.cat((inp, sol), dim=0)\n",
        "\n",
        "      x = cat[:-1].clone()\n",
        "      y= cat[1:].clone()\n",
        "\n",
        "      y[:self.length-1] = -1\n",
        "      return x,y\n",
        "\n",
        "train_dataset = SortDataset('train')\n",
        "test_dataset = SortDataset('test')\n",
        "x,y = train_dataset[0]\n",
        "for a,b in zip(x,y):\n",
        "  print(int(a), int(b))\n",
        "\n",
        "from mingpt.model import GPT\n",
        "\n",
        "model_config = gpt.get_default_config()\n",
        "model_config.model_type = \"gpt-nano\"\n",
        "model_config.vocab_size = train_dataset.get_vocab_size()\n",
        "model_config.block_size = train_dataset.get_block_size()\n",
        "model = gpt(model_config)\n",
        "\n",
        "from mingpt.trainer import Trainer\n",
        "\n",
        "train_config = trainer.get_default_config()\n",
        "train_config.learning_rate = 5e-4\n",
        "train_config.max_iters = 2000\n",
        "train_config.num_workers = 0\n",
        "trainer = Trainer(train_config, model, train_dataset)\n",
        "\n",
        "def batch_end_callback(trainer):\n",
        "  if trainer.iter_num % 100 == 0:\n",
        "    print(f\"iter_dt{trainer.iter_dt * 1000:.2f} ms; iter{trainer.iter_num}: train loss {trainer.loss.item():.5f} \")\n",
        "\n",
        "trainer.set_callback(\"on_batch_end\", batch_end_callback)\n",
        "\n",
        "trainer.run()\n",
        "\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "OKWFfzw0jL11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_split(trainer, split, max_batches):\n",
        "  dataset = {'train': train_dataset, 'test':test_dataset}[split]\n",
        "  n = train_dataset.length\n",
        "  results = []\n",
        "  mistakes_printed_already = 0\n",
        "  loader = DataLoader(dataset, batch_size=100,num_workers=0, drop_last = false)\n",
        "  for b, (x,y) in enumerate(loader):\n",
        "    x = x.to(trainer.device)\n",
        "    y = y.to(trainer.device)\n",
        "    inp = x[:,:n]\n",
        "    sol = y[:,-n:]\n",
        "    cat = model.generate(inp, n, do_sample= false)\n",
        "    sol_candidate = cat[:,n:]\n",
        "    correct = (sol == sol_candidate).all(1).cpu()\n",
        "    for i in range(x.size(0)):\n",
        "      results.append(int(correct[i]))\n",
        "      if not correct[i] and mistakes_printed_already < 3:\n",
        "        mistakes_printed_already += 1\n",
        "        print(\"gpt ..%s sorted is %s but gt is %s\" % (inp[i].tolist(), sol_candidate[i].tolist(), sol[i].tolist()))\n",
        "    if max_batches is not none and b+1 >= max_batches:\n",
        "      break\n",
        "  rt = torch.tensor(results, dtype = torch.float)\n",
        "  print(\"%s funal score %d/%d = %.2f %% correct\" % (split, rt.sum(), len(results), 100 *rt.mean()))\n",
        "  return rt.sum()\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_score = eval_split(trainer, \"train\", max_batches=50)\n",
        "  test_score =eval_split(trainer, \"test\", max_batches=50)\n",
        "\n",
        "n = train_dataset.length\n",
        "inp = torch.tensor([[0,0,2,1,0,1]], dtype = torch.long).to(trainer.device)\n",
        "assert inp[0].nelements() == n\n",
        "with torch.nograd():\n",
        "  cat = model.generate(inp, n, do_sample=false)\n",
        "sol = torch.sort(inp[0])[0]\n",
        "sol_candidate = cat[:, n:]\n",
        "print(\"input sequence :\", inp.tolist())\n",
        "print(\"predicted sorted:\", sol_candidate.tolist())\n",
        "print(\"get sort :\", sol.tolist())\n",
        "print(\"matches :\", bool((sol == sol_candidate).all()))"
      ],
      "metadata": {
        "id": "oS6WrgBhrhdf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}